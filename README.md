# Estudo sobre a Aplica√ß√£o de Fine-Tuning na Robotica Educacional 

Este reposit√≥rio abriga um estudo abrangente que investiga a converg√™ncia entre a <b>Intelig√™ncia Artificial (IA)</b> e a <b>rob√≥tica educacional</b>, propondo a utiliza√ß√£o do <b><i>fine-tuning</i></b> como solu√ß√£o para os desafios enfrentados por equipes nesse contexto. Desde a concep√ß√£o at√© os avan√ßos atuais, a IA desempenha um papel fundamental na sociedade, e a rob√≥tica educacional, focada em <b><i>STEM</i></b>, adota pr√°ticas inovadoras para educar alunos, mas enfrenta obst√°culos como escassez de recursos e disparidades em competi√ß√µes.

## Objetivo do Estudo üéØ
O objetivo central deste trabalho √© explorar a aplica√ß√£o do fine-tuning como uma ferramenta para disseminar conhecimento de maneira equitativa entre equipes de rob√≥tica educacional. Buscamos superar obst√°culos, impulsionar o desenvolvimento e fortalecer a comunidade por meio dessa abordagem inovadora.

Aqui s√£o encontrados todos os c√≥digos e arquivos relacionados ao desenvolvimento da aplica√ß√£o.

## Desenvolvimento üî®

O projeto √© dividido em tr√™s partes principais:

1. **<i>Backend</i>:** Consome o modelo criado atrav√©s da <i>API</i> da OpenAI e exp√µe uma rota, por meio do <i>fastify</i> para conex√£o com o <i>frontend</i>. Tamb√©m atua nas l√≥gicas de neg√≥cio, tais como a valida√ß√£o dos dados e o envio de informa√ß√µes.


2. **<i>Frontend</i>:** Respons√°vel pela intera√ß√£o do usu√°rio com o modelo treinado, bem como a inser√ß√£o das informa√ß√µes da equipe. Foram criados componentes espec√≠ficos para cada parte utilizando os <i>React hooks</i> para gerenciar os estados e enviar os dados nas requisi√ß√µes para o <i>backend</i>.


3. **<i>Fine-tuning:</i>** Aqui s√£o aplicados os fundamentos de <i>Machine Learning</i>, bem como as pr√°ticas recomendadas pela <a href="#openai">OpenAI</a>.
    * Primeiramente foram coletados e gerados dados sobre o tema;
    * Ent√£o foram divididos em 70% para treino e 30% para teste; 
    * Em seguida os dados foram estruturados conforme especificado na documenta√ß√£o da OpenAI (vide no exemplo abaixo ou <a href="https://github.com/jvoliveirag/TCC/blob/main/fine_tuning/data/training_data.jsonl">clique aqui</a> para visualizar todo o arquivo)

      ~~~JSON
      {"messages": [{"role": "system", "content": "Voc√™ √© um assistente t√©cnico que ajuda uma equipe da FIRST LEGO League no processo de design de rob√¥s, que inclui montagem com pe√ßas LEGO (rodas, sensores, controladores, etc), programa√ß√£o em blocos, estrat√©gia na mesa de miss√µes, documenta√ß√£o, apresenta√ß√£o, melhorias cont√≠nuas, pensamento cr√≠tico, proatividade e trabalho em equipe."}, {"role": "user", "content": "Como n√≥s podemos ajustar as configura√ß√µes do controlador PID para atender √†s necessidades espec√≠ficas do nosso rob√¥, considerando a estrat√©gia de miss√£o?"}, {"role": "assistant", "content": "Realizem testes pr√°ticos, coletem dados de desempenho, e ajustem os par√¢metros do PID com base nos resultados para otimizar o controle do rob√¥."}]}
      ~~~

    * Ap√≥s isso foram validados e algumas m√©tricas foram geradas, tais como (arquivo de exemplo - gerado no primeiro treinamento):

      ```
      Num samples: 196
      No errors found
      Num examples missing system message: 0
      Num examples missing user message: 0

      Distribution of num_messages_per_example:
      min / max: 3, 23
      mean / median: 3.4591836734693877, 3.0
      p5 / p95: 3.0, 3.0

      Distribution of num_total_tokens_per_example:
      min / max: 65, 761
      mean / median: 121.99489795918367, 106.0
      p5 / p95: 83.0, 135.0

      Distribution of num_assistant_tokens_per_example:
      min / max: 18, 450
      mean / median: 58.755102040816325, 44.0
      p5 / p95: 33.0, 86.5

      0 examples may be over the 4096 token limit, they will be truncated during fine-tuning
      Dataset has ~23911 tokens that will be charged for during training
      By default, you'll train for 3 epochs on this dataset
      By default, you'll be charged for ~71733 tokens''
      ```

    * Com os dados validados, √© feito o <i>upload</i> do arquivo <code>.jsonl</code> para o ambiente da OpenAI, onde o novo modelo ser√° treinado;

    * Por fim, √© feito o treinamento do modelo, com base nos dados enviados e este fica dispon√≠vel para uso no <i>playground</i> da OpenAI, ou como <i>API</i>, que √© o caso deste projeto.

    <b><u>OBS.:</u></b> √© importante ressaltar que o <i>fine-tuning</i> (<i><a href="https://www.leewayhertz.com/parameter-efficient-fine-tuning/">PEFT</a></i>) permite que sejam usadas menores quantidades de dados para o treinamento do modelo.

    ***M√©tricas***

    Os gr√°ficos a seguir representam a perda no treinamento do primeiro e do √∫ltimo modelo gerados. 
    
    <img src="./images/graficos_perda.png">
    
    O primeiro gr√°fico exibe as perdas (eixo y) no treinamento, podendo ser observada grande varia√ß√£o ao longos dos ‚Äúpassos‚Äù (eixo x). O resultado final pr√≥ximo de 1, vindo de uma crescente e inciando uma queda, mostra que ainda √© poss√≠vel reduzir significativamente as perdas e aproximar do valor ideal (0), o que j√° pode ser observado no segundo gr√°fico.


## Funcionamento ‚öôÔ∏è

1. Clone este reposit√≥rio em sua m√°quina;

2. Em seguida, para instalar as depend√™ncias, nos diret√≥rios do /frontend e /backend - para cada um - execute:

```
npm install
```

3. Na sequ√™ncia, execute o comando a seguir para rodar a aplica√ß√£o (tanto para o <i>front</i> quanto para o <i>backend</i>):
```
npm run dev
```

4. Para iniciar a comunica√ß√£o com o banco de dados (abstra√ß√£o - <i>ORM</i>)
```
npx prisma studio
```

Ap√≥s estes passos a aplica√ß√£o estar√° pronta para uso, o qual √© demonstrado no v√≠deo dispon√≠vel em: https://youtu.be/bqWryQXb0RM.

<b><u>OBS.:</u></b> Os endpoints podem ser testados diretamente no arquivo <code>routes.http</code>

## Requisitos üìã
* Python <i>(v3.10)</i>
* Numpy
* OpenAI <i>(API key e lib)</i>
* TypeScript <i>(v5.0.2)</i>
* ReactJS <i>(v18.2.0)</i>
* TailwindCSS
* Axios
* NodeJS <i>(v18.17.1)</i>
* Fastify <i>(v4.23.0)</i>
* PrismaORM <i>(v5.2.0)</i>

## Implementa√ß√µes futuras üí°
* Adequa√ß√£o do banco de dados;
* Testes automatizados, <i>CI/CD</i> e lan√ßar oficialmente;
* Salvar e poder selecionar prompts para consultar ou refaz√™-los;
* Sele√ß√£o de modelos para diferentes competi√ß√µes, categorias, etc;
* Customiza√ß√£o dos modelos (Open-source).

## Refer√™ncias üìö

<b><a id="openai">OpenAI</a>:</b> https://platform.openai.com/docs/guides/fine-tuning

<b>OpenAI Cookbook:</b> https://cookbook.openai.com/examples/chat_finetuning_data_prep


