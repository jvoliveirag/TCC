# Estudo sobre a Aplica√ß√£o de Fine-Tuning na Robotica Educacional 

Este reposit√≥rio abriga um estudo abrangente que investiga a converg√™ncia entre a <b>Intelig√™ncia Artificial (IA)</b> e a <b>rob√≥tica educacional</b>, propondo a utiliza√ß√£o do <b><i>fine-tuning</i></b> como solu√ß√£o para os desafios enfrentados por equipes nesse contexto. Desde a concep√ß√£o at√© os avan√ßos atuais, a IA desempenha um papel fundamental na sociedade, e a rob√≥tica educacional, focada em <b><i>STEM</i></b>, adota pr√°ticas inovadoras para educar alunos, mas enfrenta obst√°culos como escassez de recursos e disparidades em competi√ß√µes.

## Objetivo do Estudo üéØ
O objetivo central deste trabalho √© explorar a aplica√ß√£o do fine-tuning como uma ferramenta para disseminar conhecimento de maneira equitativa entre equipes de rob√≥tica educacional. Buscamos superar obst√°culos, impulsionar o desenvolvimento e fortalecer a comunidade por meio dessa abordagem inovadora.

Aqui s√£o encontrados todos os c√≥digos e arquivos relacionados ao desenvolvimento da aplica√ß√£o.

## Desenvolvimento üî®

O projeto √© dividido em tr√™s partes principais:
1. **Backend:**
2. **Frontend:**
3. **Fine-tuning:** Nesta etapa foram aplicados os fundamentos de Machine Learning, bem como as pr√°ticas recomendadas pela <a href="#openai">OpenAI</a>.
    * Primeiramente foram coletados e gerados dados sobre o tema;
    * Ent√£o foram divididos em 70% para treino e 30% para teste; 
    * Em seguida os dados foram estruturados conforme especificado na documenta√ß√£o da OpenAI (vide no exemplo abaixo ou <a href="https://github.com/jvoliveirag/TCC/blob/main/fine_tuning/data/training_data.jsonl">clique aqui</a> para visualizar todo o arquivo)

      ~~~JSON
      {"messages": [{"role": "system", "content": "Voc√™ √© um assistente t√©cnico que ajuda uma equipe da FIRST LEGO League no processo de design de rob√¥s, que inclui montagem com pe√ßas LEGO (rodas, sensores, controladores, etc), programa√ß√£o em blocos, estrat√©gia na mesa de miss√µes, documenta√ß√£o, apresenta√ß√£o, melhorias cont√≠nuas, pensamento cr√≠tico, proatividade e trabalho em equipe."}, {"role": "user", "content": "Como n√≥s podemos ajustar as configura√ß√µes do controlador PID para atender √†s necessidades espec√≠ficas do nosso rob√¥, considerando a estrat√©gia de miss√£o?"}, {"role": "assistant", "content": "Realizem testes pr√°ticos, coletem dados de desempenho, e ajustem os par√¢metros do PID com base nos resultados para otimizar o controle do rob√¥."}]}
      ~~~

    * Ap√≥s isso foram validados e algumas m√©tricas foram geradas, tais como:

      ```
      Num samples: 196
      No errors found
      Num examples missing system message: 0
      Num examples missing user message: 0

      Distribution of num_messages_per_example:
      min / max: 3, 23
      mean / median: 3.4591836734693877, 3.0
      p5 / p95: 3.0, 3.0

      Distribution of num_total_tokens_per_example:
      min / max: 65, 761
      mean / median: 121.99489795918367, 106.0
      p5 / p95: 83.0, 135.0

      Distribution of num_assistant_tokens_per_example:
      min / max: 18, 450
      mean / median: 58.755102040816325, 44.0
      p5 / p95: 33.0, 86.5

      0 examples may be over the 4096 token limit, they will be truncated during fine-tuning
      Dataset has ~23911 tokens that will be charged for during training
      By default, you'll train for 3 epochs on this dataset
      By default, you'll be charged for ~71733 tokens''
      ```

    * Feita a valida√ß√£o, √© feito  o upload do arquivo .jsonl para o ambiente da OpenAI, onde o novo modelo ser√° treinado;

    * Por fim, √© feito o treinamento do modelo, com base nos dados enviados e este fica dispon√≠vel para uso no playground da OpenAI, ou como <i>API</i>, que √© o caso deste projeto.

    <b>OBS.:</b> √© importante ressaltar que o <i>fine-tuning</i> (<i><a href="https://www.leewayhertz.com/parameter-efficient-fine-tuning/">PEFT</a></i>) permite que sejam usadas menores quantidades de dados para o treinamento do modelo.

## Funcionamento ‚öôÔ∏è


## Requisitos üìã
* Python 3.10
* Numpy
* OpenAI (Conta/API key e lib)

## Implementa√ß√µes futuras üí°


## Refer√™ncias üìö

<b><a id="openai">OpenAI</a>:</b> https://platform.openai.com/docs/guides/fine-tuning

<b>OpenAI Cookbook:</b> https://cookbook.openai.com/examples/chat_finetuning_data_prep


